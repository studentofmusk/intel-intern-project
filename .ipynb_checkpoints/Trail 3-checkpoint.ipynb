{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390f2b24-7cb9-4604-bbfb-a0bbfde77af8",
   "metadata": {},
   "source": [
    "# Step 2: Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1ecb7c-0d4a-42c7-b820-b40566430054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe6ea605-e74b-40e7-9d75-cd8c56502c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: \"Services Provided\", \n",
    "    1: \"Payment\", \n",
    "    2: \"Term\", \n",
    "    3: \"Confidentiality\", \n",
    "    4: \"Termination\", \n",
    "    5: \"Governing Law\", \n",
    "    6: \"Signatures\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7433b2-d1f6-4ad1-9468-6d93189f94ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake: Faker = Faker()\n",
    "\n",
    "# Creating Contract Text using Faker \n",
    "def generate_contract_text() -> str:\n",
    "    # generate random details\n",
    "    service_provider_name = fake.company()\n",
    "    client_name = fake.company()\n",
    "    amount = fake.random_number(digits=5)\n",
    "    start_date = fake.date_this_year()\n",
    "    end_date = fake.date_this_year()\n",
    "    state = fake.state()\n",
    "    notice_days = fake.random_int(min=30, max=90)\n",
    "\n",
    "    # Contract text template\n",
    "    datasets =[\n",
    "        [f\"{service_provider_name} agrees to provide the following services to {client_name}. services are service1 service2, service3.\", 0],\n",
    "        [f\"{client_name} agrees to pay {service_provider_name} the amount of ${amount} for the services described above. Payment shall be made within {notice_days} days of receiving an invoice from {service_provider_name}.\", 1],\n",
    "        [f\"This contract will commence on {start_date} and will continue until {end_date} unless terminated earlier in accordance with the Termination clause.\", 2],\n",
    "        [f\"Both parties agree to maintain the confidentiality of any proprietary or confidential information disclosed during the term of this contract. This obligation will continue beyond the termination of this contract.\", 3],\n",
    "        [f\"Either party may terminate this contract with {notice_days} days written notice to the other party. In the event of termination, {service_provider_name} will be compensated for all services performed up to the date of termination.\", 4],\n",
    "        [f\"This contract shall be governed by and construed in accordance with the laws of the State of {state}.\", 5],\n",
    "        [f\"{service_provider_name}\", 6],\n",
    "        [f\"{client_name}\", 6]\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994fb9e6-4171-4206-84f5-9b52084f6065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_contract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac1a6b0-f839-45a5-8547-045063981e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = generate_contract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea4fc511-23d7-4b35-8a9f-a78f6497add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = []\n",
    "for i in range(10):\n",
    "    all_df.append(generate_contract_text())\n",
    "df_concat = pd.concat(all_df)\n",
    "df_concat.columns = [\"features\", \"label\"]\n",
    "df_concat.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d859a-0192-44c6-b54d-d3b7802c2103",
   "metadata": {},
   "source": [
    "# Step 3: Fine Tune The Bert Model to classify Clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb982b1-898b-4abf-933f-aa0dc7c10263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lozano-Ellis agrees to provide the following s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day, Morrison and Vega agrees to pay Lozano-El...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This contract will commence on 2024-06-08 and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both parties agree to maintain the confidentia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Either party may terminate this contract with ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  label\n",
       "0  Lozano-Ellis agrees to provide the following s...      0\n",
       "1  Day, Morrison and Vega agrees to pay Lozano-El...      1\n",
       "2  This contract will commence on 2024-06-08 and ...      2\n",
       "3  Both parties agree to maintain the confidentia...      3\n",
       "4  Either party may terminate this contract with ...      4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6787ba82-111b-45fb-8ab2-cf1b39c0b483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655d32c6-d543-4b6f-be9a-bfe622f2361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Both parties agree to maintain the confidentia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Either party may terminate this contract with ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>This contract shall be governed by and constru...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Both parties agree to maintain the confidentia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Both parties agree to maintain the confidentia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              features  label\n",
       "331  Both parties agree to maintain the confidentia...      3\n",
       "212  Either party may terminate this contract with ...      4\n",
       "301  This contract shall be governed by and constru...      5\n",
       "235  Both parties agree to maintain the confidentia...      3\n",
       "19   Both parties agree to maintain the confidentia...      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and Test data split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df.label)\n",
    "# Check the dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33598b41-1c71-4a27-a5f0-31d5c5ec0361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "6    80\n",
       "3    40\n",
       "4    40\n",
       "5    40\n",
       "1    40\n",
       "0    40\n",
       "2    40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2335d50-e066-452a-855d-31e915adbc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "6    20\n",
       "2    10\n",
       "4    10\n",
       "3    10\n",
       "1    10\n",
       "5    10\n",
       "0    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6153b-df25-4c27-9bc4-e7a1ad2e5100",
   "metadata": {},
   "source": [
    "### Tokenize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f501b586-3431-4f71-9aa5-3807bf41cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load Bert Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize  the input text \n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4412c1b-a038-49e7-9f35-7be6b416e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df['features'].values\n",
    "val_texts = val_df['features'].values\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "val_encodings = tokenize_function(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25751777-82b5-4fd2-b5a7-c7f5d6847726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2119,  4243,  5993,  2000,  5441,  1996, 18777,  3012,  1997,\n",
       "         2151, 16350,  2030, 18777,  2592, 21362,  2076,  1996,  2744,  1997,\n",
       "         2023,  3206,  1012,  2023, 14987,  2097,  3613,  3458,  1996, 18287,\n",
       "         1997,  2023,  3206,  1012,   102,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604e20ab-f4da-49f3-92d2-786771183133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ContractDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key:val[idx] for key, val in self.encodings.items()}\n",
    "        item['label'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_labels = train_df['label'].values\n",
    "val_labels = val_df['label'].values\n",
    "\n",
    "train_dataset = ContractDataset(train_encodings, train_labels)\n",
    "val_dataset = ContractDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ddc3c24-1bd4-47a7-b268-d7b3c4be7ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2119,  4243,  5993,  2000,  5441,  1996, 18777,  3012,  1997,\n",
       "          2151, 16350,  2030, 18777,  2592, 21362,  2076,  1996,  2744,  1997,\n",
       "          2023,  3206,  1012,  2023, 14987,  2097,  3613,  3458,  1996, 18287,\n",
       "          1997,  2023,  3206,  1012,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'label': tensor(3)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Dataset\n",
    "example = iter(train_dataset)\n",
    "example_item = next(example)\n",
    "example_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5be51-fca9-4438-bceb-c38c05fbd4de",
   "metadata": {},
   "source": [
    "### Fine-Tune the BERT Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00aac404-3734-4b90-9182-67215829a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler, AdamW\n",
    "\n",
    "# Load the Bert model of sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0026137f-2c9f-4d12-95e1-c21ac3f22818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae637f02-8a38-4123-9317-1e1c97619157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41114adc-97d0-4c1f-a78a-edc6b7b5d4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\torchtut\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0072647355496884\n",
      "Epoch 2, Loss: 0.21494141407310963\n",
      "Epoch 3, Loss: 0.17988903261721134\n",
      "Epoch 4, Loss: 0.17756499648094176\n",
      "Epoch 5, Loss: 0.17544155176728965\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "NUM_EPOCHS = 5\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    avg_train_loss = total_loss/len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {avg_train_loss}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48427210-3ae7-48be-bd79-9f882c6d716b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:1.0000\n"
     ]
    }
   ],
   "source": [
    "# Validation Loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(output.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = correct / total\n",
    "print(f\"Validation Accuracy:{accuracy:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b9879e9-eaf3-4d70-ae7e-1f23b8df5e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./fine_tuned_bert\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model_save_path = './fine_tuned_bert'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9016b-b8bd-491b-b2d8-f38cd38a09e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "004c9d61-4adc-41ca-9130-0b89323e4b66",
   "metadata": {},
   "source": [
    "# Step 4: Use the Fine Tuned Bert model for clause prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbef3720-1e3c-4440-9fef-07fb4354a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies \n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fb5fd8-0723-4ddb-8157-b78920b4a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine tuned model \n",
    "model_load_path = \"./fine_tuned_bert\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_load_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11510744-e277-47c6-ba3a-e19e4c449a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "785375f5-bdc9-41f7-a092-250a1394afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, truncation=True, max_length=128, return_tensors='pt', padding=True)\n",
    "\n",
    "    # Move inputs to GPU if available\n",
    "    inputs = {key:val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    # Perform inference \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1)\n",
    "        return predicted_class.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82fcfa14-5451-4956-ab57-74352ca69db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\torchtut\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example text for inference\n",
    "example_text = \"Cole LLC agrees to provide the following services to Hines, Munoz and Dennis. services are service1 service2, service3.\"\n",
    "predicted_class = predict(example_text)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "904ae716-f6bd-42fb-b881-9225c0aac10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both parties agree to maintain the confidentiality of any proprietary or confidential information disclosed during the term of this contract. This obligation will continue beyond the termination of this contract.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "random_sample = df.sample(1)\n",
    "print(random_sample['features'].iloc[0])\n",
    "print(random_sample['label'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cab05098-5945-46b8-a6ea-19a652001b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual :Governing Law\n",
      "Predicted : Governing Law\n",
      "\n",
      "\n",
      "Actual :Governing Law\n",
      "Predicted : Governing Law\n",
      "\n",
      "\n",
      "Actual :Termination\n",
      "Predicted : Termination\n",
      "\n",
      "\n",
      "Actual :Term\n",
      "Predicted : Term\n",
      "\n",
      "\n",
      "Actual :Signatures\n",
      "Predicted : Signatures\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random_sample = df.sample(1)\n",
    "    example_text_2 = random_sample['features'].iloc[0]\n",
    "    example_class_2 = random_sample['label'].iloc[0]\n",
    "    predicted_class = predict(example_text_2)\n",
    "    print(f\"Actual :{classes[example_class_2]}\\nPredicted : {classes[predicted_class]}\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9951118-5333-4e51-939c-5145ce3a7402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bf6aa-5eb2-4904-8d58-7d289b4e05f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9157b-8556-4b91-857d-93fee07f9d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9afe6f-211e-4ffb-8ea5-0e17b9f4fb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0df04ede-528b-48b1-a185-00e218a6cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = {\"a\":[2, 243, 2],\"b\":[43, 23, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01e840c3-c704-4b56-8c1b-3df14c676764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summa(a, b):\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca2d31e6-1bef-4a28-b9af-9eb2c75b2045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 243, 2], [43, 23, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summa(**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931ee53-de69-4306-8683-f9c1860b71de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062414c-4724-4534-8c36-95ffd221e13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d2207-ec65-4ce4-bec3-93cc5f915623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392e23f-b5ef-4bdb-b7d4-3ecb53f85bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the document\n",
    "document_path = 'pdf'\n",
    "doc = fitz.open(document_path)\n",
    "\n",
    "# Extract text from PDF\n",
    "def extract_text(doc):\n",
    "    text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Parse the text into clauses and sub-clauses\n",
    "def parse_clauses(text):\n",
    "    clauses = re.split(r'\\b\\d+\\.\\s', text)[1:]  # Splitting by numbered headings\n",
    "    parsed_clauses = {}\n",
    "    for i, clause in enumerate(clauses, start=1):\n",
    "        sub_clauses = re.split(r'\\b[a-z]\\)\\s', clause)  # Splitting sub-clauses\n",
    "        parsed_clauses[f'Clause {i}'] = sub_clauses\n",
    "    return parsed_clauses\n",
    "\n",
    "# Classify the content using a pre-trained text classification model\n",
    "def classify_clauses(parsed_clauses):\n",
    "    classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "    labels = [\"Services Provided\", \"Payment\", \"Term\", \"Confidentiality\", \"Termination\", \"Governing Law\", \"Signatures\"]\n",
    "    \n",
    "    classified_clauses = {}\n",
    "    for clause, sub_clauses in parsed_clauses.items():\n",
    "        classified_clauses[clause] = []\n",
    "        for sub_clause in sub_clauses:\n",
    "            result = classifier(sub_clause, candidate_labels=labels)\n",
    "            classified_clauses[clause].append((sub_clause, result['labels'][0]))\n",
    "    return classified_clauses\n",
    "\n",
    "# Main script execution\n",
    "text = extract_text(doc)\n",
    "parsed_clauses = parse_clauses(text)\n",
    "classified_clauses = classify_clauses(parsed_clauses)\n",
    "\n",
    "# Print the parsed and classified clauses\n",
    "for clause, sub_clauses in classified_clauses.items():\n",
    "    print(f\"{clause}:\")\n",
    "    for sub_clause, classification in sub_clauses:\n",
    "        print(f\"  {classification}: {sub_clause}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
